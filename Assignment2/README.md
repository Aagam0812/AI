# ğŸš€ LLM Exploration with Google Colab

Welcome to the **LLM Exploration** repository! Dive into the world of Large Language Models using Google Colab. We'll fine-tune models, explore features, and run LLMs both locally and in the cloud! ğŸ‰

---

## ğŸ“‘ Table of Contents

- [Introduction](#introduction)
- [Prerequisites](#prerequisites)
- [Task A: LLama-Factory ğŸ¦™](#task-a-llama-factory-)
  - [A.1 Supervised Fine-Tuning ğŸ¯](#a1-supervised-fine-tuning-)
  - [A.2 DPO Training ğŸ‹ï¸â€â™‚ï¸](#a2-dpo-training-ï¸)
  - [A.3 PPO Training ğŸ¤–](#a3-ppo-training-)
- [Task B: LM Studio Features ğŸ§ª](#task-b-lm-studio-features-)
  - [B.1 Gemma 2B & PDF Q&A ğŸ“„](#b1-gemma-2b--pdf-qa-)
- [Task C: Running LLMs Locally with Ollama ğŸ’»](#task-c-running-llms-locally-with-ollama-)
  - [C.1 Install Ollama & Run Gemma 2B ğŸ–¥ï¸](#c1-install-ollama--run-gemma-2b-ï¸)
  - [C.2 Multimodal Capabilities ğŸŒ](#c2-multimodal-capabilities-)
  - [C.3 REST API Showcase ğŸ“¡](#c3-rest-api-showcase-)
  - [C.4 Run Ollama in Google Colab â˜ï¸](#c4-run-ollama-in-google-colab-ï¸)
  - [C.5 Open WebUI Features ğŸŒŸ](#c5-open-webui-features-)
- [Task D: Dify.ai Workflow Capabilities ğŸ› ï¸](#task-d-difyai-workflow-capabilities-ï¸)



---

## Introduction

In this repository, we've curated a set of Google Colab notebooks and resources to help you:

- Fine-tune LLMs with LLama-Factory.
- Explore LM Studio's features.
- Run LLMs locally using Ollama.
- Utilize Dify.ai for advanced workflows.

---

**Access all the videos Demo [here](https://drive.google.com/drive/folders/1zMOjqVjJwiUI6F614NnQ7MVZidUssZlT?usp=sharing).**

---


## Task A: LLama-Factory ğŸ¦™

### A.1 Supervised Fine-Tuning ğŸ¯

Demonstrate supervised fine-tuning using LoRA or QLoRA with LLama-Factory.

### A.2 DPO Training ğŸ‹ï¸â€â™‚ï¸

Showcase Direct Preference Optimization (DPO) training to improve preference-based outputs.

### A.3 PPO Training ğŸ¤–

Demonstrate Proximal Policy Optimization (PPO) training to enhance model performance.

---

## Task B: LM Studio Features ğŸ§ª

### B.1 Gemma 2B & PDF Q&A ğŸ“„

Download Gemma 2B and interact with a PDF document by asking questions related to its content.

---

## Task C: Running LLMs Locally with Ollama ğŸ’»

### C.1 Install Ollama & Run Gemma 2B ğŸ–¥ï¸

Run the Gemma 2B model locally using Ollama and test its responses.

### C.2 Multimodal Capabilities ğŸŒ

Explore Ollama's support for multimodal models by testing various inputs like text and images.

### C.3 REST API Showcase ğŸ“¡

Utilize Ollama's REST API with practical examples to communicate with the model programmatically.

### C.4 Run Ollama in Google Colab â˜ï¸

Operate Ollama within a Google Colab environment, following a step-by-step guide for setup.

### C.5 Open WebUI Features ğŸŒŸ

Demonstrate Ollama's features using Open WebUI to enhance user interaction through a web interface.

---

## Task D: Dify.ai Workflow Capabilities ğŸ› ï¸

Utilize Dify.ai to demonstrate advanced workflows, including:

- RAG Engine
- Agent Configuration
- Workflow Automation
- Observability Tools
- Local Deployment


