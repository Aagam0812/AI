# 🚀 LLM Exploration with Google Colab

Welcome to the **LLM Exploration** repository! Dive into the world of Large Language Models using Google Colab. We'll fine-tune models, explore features, and run LLMs both locally and in the cloud! 🎉

---

## 📑 Table of Contents

- [Introduction](#introduction)
- [Prerequisites](#prerequisites)
- [Task A: LLama-Factory 🦙](#task-a-llama-factory-)
  - [A.1 Supervised Fine-Tuning 🎯](#a1-supervised-fine-tuning-)
  - [A.2 DPO Training 🏋️‍♂️](#a2-dpo-training-️)
  - [A.3 PPO Training 🤖](#a3-ppo-training-)
- [Task B: LM Studio Features 🧪](#task-b-lm-studio-features-)
  - [B.1 Gemma 2B & PDF Q&A 📄](#b1-gemma-2b--pdf-qa-)
- [Task C: Running LLMs Locally with Ollama 💻](#task-c-running-llms-locally-with-ollama-)
  - [C.1 Install Ollama & Run Gemma 2B 🖥️](#c1-install-ollama--run-gemma-2b-️)
  - [C.2 Multimodal Capabilities 🌐](#c2-multimodal-capabilities-)
  - [C.3 REST API Showcase 📡](#c3-rest-api-showcase-)
  - [C.4 Run Ollama in Google Colab ☁️](#c4-run-ollama-in-google-colab-️)
  - [C.5 Open WebUI Features 🌟](#c5-open-webui-features-)
- [Task D: Dify.ai Workflow Capabilities 🛠️](#task-d-difyai-workflow-capabilities-️)



---

## Introduction

In this repository, we've curated a set of Google Colab notebooks and resources to help you:

- Fine-tune LLMs with LLama-Factory.
- Explore LM Studio's features.
- Run LLMs locally using Ollama.
- Utilize Dify.ai for advanced workflows.

---

**Access all the videos Demo [here](https://drive.google.com/drive/folders/1zMOjqVjJwiUI6F614NnQ7MVZidUssZlT?usp=sharing).**

---


## Task A: LLama-Factory 🦙

### A.1 Supervised Fine-Tuning 🎯

Demonstrate supervised fine-tuning using LoRA or QLoRA with LLama-Factory.

### A.2 DPO Training 🏋️‍♂️

Showcase Direct Preference Optimization (DPO) training to improve preference-based outputs.

### A.3 PPO Training 🤖

Demonstrate Proximal Policy Optimization (PPO) training to enhance model performance.

---

## Task B: LM Studio Features 🧪

### B.1 Gemma 2B & PDF Q&A 📄

Download Gemma 2B and interact with a PDF document by asking questions related to its content.

---

## Task C: Running LLMs Locally with Ollama 💻

### C.1 Install Ollama & Run Gemma 2B 🖥️

Run the Gemma 2B model locally using Ollama and test its responses.

### C.2 Multimodal Capabilities 🌐

Explore Ollama's support for multimodal models by testing various inputs like text and images.

### C.3 REST API Showcase 📡

Utilize Ollama's REST API with practical examples to communicate with the model programmatically.

### C.4 Run Ollama in Google Colab ☁️

Operate Ollama within a Google Colab environment, following a step-by-step guide for setup.

### C.5 Open WebUI Features 🌟

Demonstrate Ollama's features using Open WebUI to enhance user interaction through a web interface.

---

## Task D: Dify.ai Workflow Capabilities 🛠️

Utilize Dify.ai to demonstrate advanced workflows, including:

- RAG Engine
- Agent Configuration
- Workflow Automation
- Observability Tools
- Local Deployment


